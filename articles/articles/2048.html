<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mazen Messai - Comparative Study Between Minimax and MCTS for 2048</title>
    <!-- Link to FontAwesome for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="stylesheet" href="../../styles/default_index.css">
    <link rel="stylesheet" href="../../styles/articles.css">
    <script src="../../scripts/main.js"></script>
    <!-- MathJax for rendering LaTeX -->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <!-- Sidebar -->
    <aside class="sidebar" id="sidebar">
        <nav>
            <!-- Pour fermer la navbar responsive -->
            <a href="javascript:void(0);" class="icon mobile-screen" onclick="toggleSideBar()">
                <i class="fa fa-close"></i>
            </a>
            <!-- Liens de la NavBar -->
            <ul>
                <li><a href="../default_index.html">Welcome</a></li>
                <li><a href="blog.html">Engineering Course & Articles</a></li>
                <li><a href="international_mobility.html">International mobility</a></li>
                <li><a href="civic_engagement.html">Civic Engagment</a></li>
                <li><a href="career.html">Career Developpement</a></li>
                <li><a href="sports_and_activities.html">Sport & Other activities</a></li>
            </ul>
            <!-- Icons socials -->
            <div class="social-icons">
                <!-- LinkedIn and GitHub icons -->
                <a href="https://www.linkedin.com/in/mazen-messai-4587a41bb/" target="_blank">
                    <i class="fab fa-linkedin fa-2x"></i>
                </a>
                <a href="https://github.com/Mazen-Messai" target= "_blank">
                    <i class="fab fa-github fa-2x"></i>
                </a>
            </div>
        </nav>
    </aside>
    
    <div class="mobile-screen responsive-sidebar">
        <a href="javascript:void(0);" class="icon" onclick="toggleSideBar()">
            <i class="fa fa-bars"></i>
          </a>
        <a href="../../default_index.html" class="responsive-title">Mazen Messai</a>
    </div>
    <!-- Main Content -->
    <main>
        <header class="study-content">
            <h1>Comparative Study Between Minimax Algorithm and MCTS for the Game 2048</h1>
            <p>Most off us know 2048, and most of us play this game "instinctivly", but how about algorithm? My close friend <a href="https://www.linkedin.com/in/tiromar/">Omar</a> and I have explored the subjet during our second year of Classe Prépatatoire, and here is a little article explaining what we did and our results !  </p>
        </header>

        <section class="study-content">
            <h2>Abstract</h2>
            <p>
                The 2048 game, a widely recognized digital puzzle, presents a unique blend of chance and strategy, making it an ideal candidate for artificial intelligence (AI) analysis. This study investigates the performance of two prominent AI algorithms—Minimax and Monte Carlo Tree Search (MCTS)—in the context of the 2048 game. The Minimax algorithm employs a comprehensive approach by exploring all possible moves while anticipating the worst-case scenarios, whereas MCTS utilizes random simulations to navigate the decision tree, offering a flexible strategy. 
            </p>
            <p>    
                Through simulations of 1000 games, the impact of randomness on game outcomes was assessed, revealing that purely random strategies often result in low scores. Subsequently, Minimax demonstrated significant potential in achieving the game's objective, yet its high computational costs limited its efficiency. In contrast, MCTS outperformed Minimax by achieving a higher success rate and requiring less computational time. The study concludes with potential enhancements for MCTS, including the integration of reinforcement learning and strategic human input in the early stages of the game, paving the way for future research and optimization in AI applications for more complex problems.
            </p>
            <h2>1. Introduction</h2>
            <p>
                The 2048 game is a digital puzzle game that became extremely popular shortly after its launch in 2014. The game is played on a 4x4 grid where tiles with equal values combine to form a tile with a higher value. The aim is to merge the tiles until you have a tile with the value 2048. Although the rules of the game are simple, the number of possible movement options and the random introduction of new tiles each turn give the game a considerable strategic depth.
            </p>
            <p>
                The game's success is linked to its ability to balance elements of chance and strategy, making each game unique. This complex nature of the game, which combines strategic decisions with random elements, makes it an excellent field of study for testing and comparing artificial intelligence algorithms.
            </p>
            <p>
                Two algorithms, Minimax and Monte Carlo Tree Search (MCTS), are often used to analyze and determine the best moves in strategic games. Minimax explores all game possibilities, anticipating the worst case to choose the best move, while MCTS uses random simulations to explore the decision tree more flexibly. In this study, I dealt with the MCTS part, while Mazen Messai took care of the Minimax part. The aim of this work is to compare the performance of these two algorithms and evaluate their respective strengths and weaknesses in the context of the 2048 game.
            </p>

            <h2>2. The role of chance in the 2048 game</h2>
            <p>
                The 2048 game involves a high degree of randomness, since after each move, a new tile (worth 2 or 4) appears randomly on the grid. To assess the impact of this random aspect, we ran a simulation of 1000 games, using different approaches based on random moves or simple rules.
            </p>
            <p>
                We tested several strategies. The first approach was to make totally random moves, where each move was chosen without any particular logic. In this configuration, the results were often very poor, with little progression towards high-value tiles.
            </p>
            <p>
                Next, we implemented a direction prioritization strategy, where certain movements such as going up or to the left were favored. The aim of this approach was to better control the positioning of tiles on the grid, but the results were limited.
            </p>
            <p>
                The results show that randomized or simple instruction-based approaches do not reliably achieve the 2048 tile. The majority of games end with relatively low scores, and the highest-value tiles obtained often don't exceed 128 or 256.
            </p>
            <p>
                The graph below shows the distribution of scores obtained after 1000 simulated games. As can be seen, the majority of games reach scores between 500 and 1500, and very few manage to exceed the 2000-point mark. 
            </p>
                <img src="..\..\ressources\ressources2048\score1.png">
                <figcaption>Fig.1 - Score distribution for 1000 random games </figcaption>
            <p>
                The following graph illustrates the distribution of tiles obtained in these simulations. It shows that the majority of games result in tiles with modest values, such as 64 or 128, and that very few games manage to generate tiles with higher values, such as 512 or 256.
            </p>
                <img src="..\..\ressources\ressources2048\scoredonut1.png">
                <figcaption>Fig.2 - Distribution of tiles obtained during simulations </figcaption>
            <p>
                These simulations clearly show that strategies based solely on chance cannot reliably beat the game. Although some simple rules can slightly improve results, they are still insufficient to maximize the chances of success.  
            </p>

            <h2>3. Minimax algorithm</h2>
            <p>
                The Minimax algorithm is one of the most commonly used methods for solving two-player game problems, simulating “maximization” and “minimization” scenarios in order to choose the optimal actions. Here, in order to get rid of the randomness, we will considerate the game as an opponent, who will place the next tiles in the scenario that will minimize our score.
            </p>
            <p>
                Minimax helps to explore all the options available at each move, and to choose the option that maximizes the chances of long-term success, taking into account not only the immediate move, but also its future consequences. Coupled with alpha-beta pruning, the Minimax algorithm becomes more efficient by reducing the number of branches to be explored in the decision tree.
            </p>
                <img src="..\..\ressources\ressources2048\arbre1.png">
                <figcaption>Fig.3 - Alpha-Beta tree </figcaption>
                <img src="..\..\ressources\ressources2048\arbre2.png">
                <figcaption>Fig.4 - Alpha-Beta tree </figcaption>
            <p>
                Figure 3 shows the basic structure of a Minimax tree. Level 0 represents the player seeking to maximize his score by choosing the best possible move from the directions (left, up, down, right). Level 1 simulates the random appearance of new tiles after the player's move, representing the “minimization” of the player's gains, as these new tiles may prevent future mergers. The process alternates between these two levels until it reaches a certain depth, at which point an evaluation function determines the quality of each board state.  
            </p>
            <p>
                In Figure 4, values are assigned to each node, illustrating the player's decision-making process. At each “max” level, the player selects the move that maximizes his potential score, while at each “min” level, he anticipates the appearance of new tiles in the least favorable locations.
            </p>
            <h3>3.1. Heuristics used by Minimax</h3>
            <p>
                To efficiently evaluate each board state in the 2048 game, the Minimax algorithm uses several heuristics. These heuristics assign a value to the different scenarios, taking into account the layout of the tiles and their potential to merge.
            </p>
            <p>
                The first important heuristic is monotony. It evaluates the arrangement of tiles in terms of their ascending or descending order. A board is considered monotonous if the values of the tiles increase or decrease in an orderly fashion, either horizontally or vertically. This arrangement makes the board easier to manage, as higher-value tiles are grouped together and therefore more likely to merge in future moves. To measure this monotony, we use the following formula :
            </p>
            \[
            \large \text{monotony} = \frac{1}{2} \sum_{i=0}^{3} \sum_{j=0}^{3} (\delta_{i,j}^{V} + \delta_{i,j}^{H})
            \]
            <p>
                In this formula, the terms \(\delta_{i,j}^{V}\) and \(\delta_{i,j}^{H}\) respectively measure the difference in values between vertically and horizontally adjacent tiles. When these differences are small, they indicate a monotonous progression across the board.
            </p>
            <p>
                The second key heuristic is regularity. This measures the differences in values between adjacent tiles and seeks to minimize these differences. A regular board features tiles whose values are close to each other, thus facilitating future mergers. This regularity is particularly important, as too great a gap between the values of adjacent tiles makes it more difficult to create new mergers in future moves. Regularity is calculated using the following formula :
            </p>
            \[
            \large\text{régularité} = - \sum_{i=0}^{3} \sum_{j=0}^{3} (d_{i,j}^{V} + d_{i,j}^{H})
            \]
            <p>
                In this formula, \(d_{i,j}^{V}\) and \(d_{i,j}^{H}\) measure the logarithmic distance between vertically and horizontally adjacent tiles. The smaller the deviation, the more regular the board is considered to be, making future mergers easier.
            </p>
            <h3>3.2. Minimax Results</h3>
            <p>
                After applying the heuristics to the Minimax algorithm, we'll discuss the results obtained for different depth configurations. The graph below (Figure 5) illustrates the results of the Minimax algorithm for three different calculation depths: 4, 5 and 6. 
            </p>
                <img src="..\..\ressources\ressources2048\3graphiquesMinimax.png">
                <figcaption>Fig.5 - Results of the Minimax algorithm at depths 4, 5 and 6, 100 games.</figcaption>
            <p>
                At a depth of 6, Minimax manages to significantly increase the proportion of games reaching tile 2048, but even at this depth, the win rate doesn't exceed 50\%. This shows that even when optimizing moves and anticipating worst-case scenarios, the algorithm is still limited by the random element introduced by the appearance of new tiles after each move. What's more, the computational time cost becomes very high at this depth, making execution of the algorithm very slow, especially for long-term simulations.
            </p>
            <p>
                The cost in computing time becomes very high at this depth. For example, at a depth of 5, each part takes an average of 20 minutes to run. Consequently, to complete the 100 simulations required for the analysis, it took almost 30 hours to run. At a depth of 6, this time becomes even more prohibitive, making it difficult to run the algorithm.
            </p>

            <h2>4. Monte Carlo Tree Search Algorithm</h2>
            <h3>4.1. How MCTS works</h3>
            <p>
                Monte Carlo Tree Search (MCTS) is a method used to make decisions in games where the next possible states are not known precisely, as in the game 2048. Unlike other algorithms such as Minimax, MCTS is particularly useful when faced with uncertainty about the evolution of the game.
            </p>
            <p>
                In 2048, the MCTS algorithm builds a game tree by simulating several games from each possible move. At each turn, several simulations are run to see how the game might evolve after a given move. Each simulation helps to estimate the potential success of a move. The algorithm then selects the move that gave the best results in the simulations and saves this decision.
            </p>
            <h3>4.1. Principle of the MCTS algorithm</h3>
            <p>
                The MCTS algorithm follows an iterative process to select the best moves in a game like 2048, where uncertainty about the future state of the game is omnipresent. The operation of MCTS can be summarized in four main phases: selection, expansion, simulation and back-propagation, but these stages form a continuous flow rather than a rigid sequence.
            </p>
            <p>
                First, the algorithm begins with selection. Based on the current state of the game, it traverses the existing decision tree, choosing the nodes (or moves) that seem most promising. This phase is guided by the Upper Confidence Bound (UCB) formula, which manages the dilemma between exploiting moves already explored or exploring new ones. The UCB formula is given by :
            </p>
            \[
            \normalsize a^* = \arg \max_{a \in A(s)} \left[ Q(s, a) + C \sqrt{\frac{\ln N(s)}{N(s, a)}} \right]
            \]
            <p>
                where A(s) represents the possible actions in the state, Q(s, a) is the average score obtained by playing a, N(s) is the number of times the state has been visited, \( N(s, a) \) the number of times the action \( a \) has been chosen, and \( C \) is a constant that regulates the balance between exploration and exploitation.
            </p>
            <p>
                Once a move has been selected, the algorithm simulates a game from that move, playing a series of random moves to a hypothetical endgame. This allows the potential success of each decision to be assessed. The result of this simulation is then used to update the estimate of previous moves in the tree. At each new round, MCTS chooses the move that has achieved the best results over the simulations. This approach enables the algorithm to make optimized decisions even in the presence of uncertainty, such as the random appearance of new tiles in the 2048 game.
            </p>
            <h3>4.2. MCTS Results</h3>
            <p>
                The MCTS algorithm proved highly effective in solving 2048 games with impressive results, even with relatively small depth due to computational time constraints. As shown in Figure 7, of the 100 simulated games, 66 reached tile 2048, and 25 even reached tile 4096. Only 8 of the games were lost, demonstrating the robustness of the algorithm in achieving optimal results.
            </p>
                <img src="..\..\ressources\ressources2048\montecarloresultat.png">
                <figcaption>Fig.6 - Results of MCTS algorithm, 100 games.</figcaption>
            <p>
                However, while these performances are promising, MCTS suffers from a time complexity that can become prohibitive with higher depth. The time complexity of MCTS is given by :
            </p>
            \[
            \large O(n \cdot m \cdot d)
            \]
            <p>
                where \(n\) is the number of simulations, \(m\) is the number of possible legal moves at each step, and (\d\) is the depth of the simulations. This means that as the depth and number of simulations increase, so does the computation time. In the conclusion, we'll look at different performance optimization methods.
            </p>
            <h2>Conclusion and possible improvements</h2>
            <p>
                In this study, we explored the performance of two algorithms for solving the 2048 game: Minimax and Monte Carlo Tree Search. Although Minimax performs well in certain contexts, it has shown significant limitations in terms of time complexity and ability to achieve consistent results. Conversely, the MCTS algorithm proved to be more effective in solving the game.
            </p>
            <p>
                Improving the performance of MCTS also involves managing its temporal complexity. One possible approach would be to start the game with a human strategy, simulating for example the first 50 moves without using MCTS, where you could still get a good position in the game without losing the game (Figure 7). This method will significantly reduce the number of unoccupied squares on the board, simplifying the problem for MCTS. 
            </p>
                <img src="..\..\ressources\ressources2048\gamesaftermoves.png">
                <figcaption>Fig.7 - Lost games by number of moves.</figcaption>
            <p>
                The integration of methods such as Reinforcement Learning, or optimization of the early stages of the game, could further enhance the performance of this algorithm. This future research will not only help us to better understand the limits of MCTS, but also to apply it to more complex problems beyond the 2048 game.
            </p>

            <h2>Bibliography</h2>
            <ol>
                <li>
                    T. Neller and C. Presser, 
                    <em>AI for 2048: Heuristic Search and Reinforcement Learning</em>, 
                    Gettysburg College, 2014. 
                    <a href="http://cs.gettysburg.edu/~tneller/papers/ccsce14-2048.pdf" target="_blank">http://cs.gettysburg.edu/~tneller/papers/ccsce14-2048.pdf</a>
                </li>
                <li>
                    M. Yato and T. Seta, 
                    <em>Complexity and Completeness of Finding Another Solution and Its Application to Puzzles</em>, 
                    International Journal of Advanced Applied Mathematics and Computer Science, 2017. 
                    <a href="https://www.ripublication.com/aama17/aamav12n1_01.pdf" target="_blank">https://www.ripublication.com/aama17/aamav12n1_01.pdf</a>
                </li>
                <li>
                    C. Scarvalone, 
                    <em>An Investigation of 2048 Using Reinforcement Learning</em>, 
                    University of Chicago, 2008. 
                    <a href="https://www.math.uchicago.edu/~may/VIGRE/VIGRE2008/REUPapers/Scarvalone.pdf" target="_blank">https://www.math.uchicago.edu/~may/VIGRE/VIGRE2008/REUPapers/Scarvalone.pdf</a>
                </li>
            </ol>
        </section>

        <footer>
            <p>&copy; 2024 Mazen Messai. All Rights Reserved.</p>
        </footer>
    </main>
</body>
</html>
